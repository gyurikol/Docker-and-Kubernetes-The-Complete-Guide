QUESTIONS AND ANSWERS
    what is a image?
        single file with all the deps and config required to run a program
    what is a container?
        instance of an image. runs a program.
    what is docker?
        docker is a platform or ecosystem around creating and running containers
    why do we use docker?
        docker makes it really easy to install and run software without worrying about setup or depenencies
    what is the docker client (docker cli)?
        tool that we issue commands to
    what is the docker server (docker daemon)?
        toold that is responsible for creating images, running containers, etc.

    what is namespacing?
        isolating resources per process (or group of processes)
    what are control groups (cgroups)?
        used to limit amount of resources used per process

    what is a dockerfile?
        configuration to define how your container should behave

    what is docker compose?
        used to start up multiple docker containers at the same time.
        automates some of the long-winded arguments we were passing to 'docker run'.
        assists in connecting containers in some automated fashion (networking).

    what are restart policies?
        they are used to state a container automatic restart policy in the event a container has crashed, stopped, etc.

    why cant i put no without quotes in docker-compose.yml file?
        no is a yaml file reserved word for false. therefore needs to be contained within single or double quotes.

    what is kubernetes?
        - system to deploy containerized apps
        - system for running many different containers over multiple different machines
    why use kubernetes?
        when you need to run many different containers with different images
    what is a node (kuberenetes)?
        virtual machine or physical computer
    what is a master (kubernetes)?
        - machines (or vm's) with a set of programs to manage nodes
        - controls what each node does
    what is a cluster (kubernetes)?
        Nodes + Master form a 'Cluster'

    what is minikube? (development environment)
        command line software you can use to setup a tiny kubernetes cluster on local computer
    what is a managed solution? (production environment)
        references to outside cloud providers that will setup an entire kubernetes cluter
        they will also handle alot of the low-level tasks required in a secure fashion
            e.g. EKS (Amazon Elastic Container Service for Kubernetes)
                 GKE (Google Cloud Kubernetes Engine)
    
    when do we want to use a pod object (k8s)?
        when we want to 'run one or more closely related containers'
    when do we want to use a services object (k8s)?
        when we want to 'set up networking in a kubernetes cluster'
    what is the 'label selector' system (k8s)?
        when we want to provide a 'service' by reference to an objects label metadata

    what is the kube-apiserver (k8s)?
        - lives in master
        - responsible for monitoring the current status of all the different nodes inside of the cluster
          to ensure that they are doing the correct thing

    what is a 'Imperative Deployment'?
        do exactly these steps to arrive at this container setup
    what is a 'Declarative Deployment'?
        our container setup should look like this, make it happen

NOTES
    > [docker run] = [docker create] + [docker start]
    > create a container
        [docker create <image name>]
            can change default startup command by writing a command after image name
    > start a container
        [docker start <container id>]
    > start a container in the background (detached mode)
        [docker start -d <image name>]
    > clean docker system
        [docker system prune]
            this will remove:
                all stopped containers
                all networks not used by at least one container
                all dangling images
                all build cache
    > get logs from a container
        [docker logs <container id>]
    > stop a container (SIGTERM)
        [docker stop <container id>]
    > kill a container (SIGKILL)
        [docker kill <contianer id>]
    > execute an additional command in a container
        [docker exec -it <container id> <command>]
            exec - run another command
            -it - allow us to provide input to the container
    > dockerfile creation flow
        1) specify a base image
        2) run some commands to install additional programs
        3) specify a command to run on container startup
    > dockerfile
        - each line is an incremental change on the prior image snapshot
        - docker creates a temporary container per line/step on dockerfile build
        - changes to early sections of the file may require recompiling of images
            as these incremental order of changes wont exist in cache
    > tagging an image (making it easey to run)
        [docker build -t gyuri/redis:latest .]
            naming convention is:
              ----------------------------------------------------
              |     gyuri       /        redis        :   latest  |
              |       ^                    ^                ^     |
              | Your docker ID     Repo/Project Name     Version  |
              ----------------------------------------------------
    > manual image generation with docker commit
        [docker commit -c <command> <container id>]
            command being the default command for the docker image
    > docker run with port mapping
        [docker run -p 8080:8080 <image id>]
                        ^    ^
            localhost port  container port
    > dockerfile specify working directory
        [WORKDIR /usr/app]
            any following command will be executed relative to this parth in the container
    > changing files that will be included in the fs snapshot will re-run and perform all steps in the dockerfile
      without refering to cache (npm install will rerun and not refer to cache)
        on tasks and steps that are expensive this is not ideal
            - the changes before were:
                COPY ./ ./
                RUN npm install
            - and changed to:
                COPY ./package.json ./
                RUN npm install
                COPY ./ ./
            - therefore the copied files will not effect the npm installation and referred snapshots if
              later changes down the track will be made to say the 'index.js' file.
                which npm install is not dependant on            
    > run an instance of the all the containers, images and services in the docker-compose.yml file
        [docker-compose up]
    > start up all our docker-compose containers, images and serverts in the docker-compose.yml file.
      but make sure you rebuild the images first.
        [docker-compose up --build]
    > start multi-container application in the background (detached mode) (**refers to docker-compose file)
        [docker-compose up -d]
    > stop multi-container application (**refers to docker-compose file)
        [docker-compose down]
    > restart policies
        "no"           - never attempt to restart this. container if it stops or crashes
        always         - if this container stops *for any reason* always attempt to restart it
        on-failure     - only restart if the container stops with an error code
        unless-stopped - always restart unless we (the developers) forcibly stop it
    > check the status of the running containers in the docker-compose.yml file
        [docker-compose ps]
    > build with custom named dockerfile
        [docker build -f <dockerfile filename> .]
            -f for the filename argument
            *still needs the . at the end to specify the build context*
    > map the pwd into the '/app' folder to access from container
        [docker run -p <localhost port>:<container port> -v $(pwd):/app <image id>]
            *map a folder that is inside a container to a folder that is outside of a container*
    > put a bookmark on a folder (e.g. node_modules)
        [docker run -p 3000:3000 -v /app/node_modules <image id>]
            - therefore /app/node_modules is set in stone, dont try mess with it, dont try and map it out
              with anything else
    > Attach local standard input, output, and error streams to a running container
        [docker attach <container id>]
    > nginx
        popular web server which upon request can purely respond with some static files
    > Dockerrun.aws.json file
        Container Definitions
    > kubectl vs minikube
        kubectl - use for managing containers in the node
        minikube - use for managing the VM itself (LOCAL ONLY!)
    > k8s 'services' object subtypes
        ClusterIP    -
        NodePort     - exposes a container to the outside world (only good for dev purposes!!!)
        LoadBalancer -
        Ingress      - 
    > kube-proxy
        every single node or member of a k8s cluster has a program called the kube-proxy
            > it is the 'one single window to the outside world'
    > NodePort Service
        nodePort property range:
            - random between 30000-32767
    > kubectl apply -f <filename"
        kubectl - CLI we use to change our Kubernetes cluster
        apply - change the current configuration of our cluster
        -f - we want to specify a file taht has the config changes
        <filename> - path to the file with the config
    > kubectl get [pods|services|*other-objects*]
        when getting services it will only report on:
            port: port that other objects will try and access to reference other pods that the service points to
            nodePort: the port we would use to try and access the service from maybe our browser
    > when we interact with the kubectl CLI command:
        when we pass a file or commands, we are nearly all the time are interacting with the 'master'.
        this performs monitoring and delegation to seperate nodes running a docker instance
    > kubernetes takeaways
        - kubnernetes is a system to deploy containerized apps
        - 'Nodes' are individual machines (or vm's) that run containers
        - 'Masters' are machines (or vm's) with a set of programs to manage nodes
        - Kubernetes did build our images - it got them from somewhere else
        - Kubernetes (the master) decided where to run each container
            \ each node can run a dissimilar set of containers
        - To deploy something, we update the desired state of the master with a config file
        - The master works constatly to meet your desired state
    > kubernetes (kubectl)
        - has the capabilities to perform commands/changes with both a 'Imperative Approach' and 'Declarative Approach'

