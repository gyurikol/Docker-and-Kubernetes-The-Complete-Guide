NOTES
    > [docker run] = [docker create] + [docker start]
    > create a container
        [docker create <image name>]
            can change default startup command by writing a command after image name
    > start a container
        [docker start <container id>]
    > start a container in the background (detached mode)
        [docker start -d <image name>]
    > clean docker system
        [docker system prune]
            this will remove:
                all stopped containers
                all networks not used by at least one container
                all dangling images
                all build cache
    > get logs from a container
        [docker logs <container id>]
    > stop a container (SIGTERM)
        [docker stop <container id>]
    > kill a container (SIGKILL)
        [docker kill <contianer id>]
    > execute an additional command in a container
        [docker exec -it <container id> <command>]
            exec - run another command
            -it - allow us to provide input to the container
    > dockerfile creation flow
        1) specify a base image
        2) run some commands to install additional programs
        3) specify a command to run on container startup
    > dockerfile
        - each line is an incremental change on the prior image snapshot
        - docker creates a temporary container per line/step on dockerfile build
        - changes to early sections of the file may require recompiling of images
            as these incremental order of changes wont exist in cache
    > tagging an image (making it easey to run)
        [docker build -t gyuri/redis:latest .]
            naming convention is:
              ----------------------------------------------------
              |     gyuri       /        redis        :   latest  |
              |       ^                    ^                ^     |
              | Your docker ID     Repo/Project Name     Version  |
              ----------------------------------------------------
    > manual image generation with docker commit
        [docker commit -c <command> <container id>]
            command being the default command for the docker image
    > docker run with port mapping
        [docker run -p 8080:8080 <image id>]
                        ^    ^
            localhost port  container port
    > dockerfile specify working directory
        [WORKDIR /usr/app]
            any following command will be executed relative to this parth in the container
    > changing files that will be included in the fs snapshot will re-run and perform all steps in the dockerfile
      without refering to cache (npm install will rerun and not refer to cache)
        on tasks and steps that are expensive this is not ideal
            - the changes before were:
                COPY ./ ./
                RUN npm install
            - and changed to:
                COPY ./package.json ./
                RUN npm install
                COPY ./ ./
            - therefore the copied files will not effect the npm installation and referred snapshots if
              later changes down the track will be made to say the 'index.js' file.
                which npm install is not dependant on            
    > run an instance of the all the containers, images and services in the docker-compose.yml file
        [docker-compose up]
    > start up all our docker-compose containers, images and serverts in the docker-compose.yml file.
      but make sure you rebuild the images first.
        [docker-compose up --build]
    > start multi-container application in the background (detached mode) (**refers to docker-compose file)
        [docker-compose up -d]
    > stop multi-container application (**refers to docker-compose file)
        [docker-compose down]
    > restart policies
        "no"           - never attempt to restart this. container if it stops or crashes
        always         - if this container stops *for any reason* always attempt to restart it
        on-failure     - only restart if the container stops with an error code
        unless-stopped - always restart unless we (the developers) forcibly stop it
    > check the status of the running containers in the docker-compose.yml file
        [docker-compose ps]
    > build with custom named dockerfile
        [docker build -f <dockerfile filename> .]
            -f for the filename argument
            *still needs the . at the end to specify the build context*
    > map the pwd into the '/app' folder to access from container
        [docker run -p <localhost port>:<container port> -v $(pwd):/app <image id>]
            *map a folder that is inside a container to a folder that is outside of a container*
    > put a bookmark on a folder (e.g. node_modules)
        [docker run -p 3000:3000 -v /app/node_modules <image id>]
            - therefore /app/node_modules is set in stone, dont try mess with it, dont try and map it out
              with anything else
    > Attach local standard input, output, and error streams to a running container
        [docker attach <container id>]
    > nginx
        popular web server which upon request can purely respond with some static files
    > Dockerrun.aws.json file
        Container Definitions
    > kubectl vs minikube
        kubectl - use for managing containers in the node
        minikube - use for managing the VM itself (LOCAL ONLY!)
    > k8s 'services' object subtypes
        ClusterIP    - exposes a set of pods to other objects in the cluster
        NodePort     - exposes a container to the outside world (only good for dev purposes!!!)
        LoadBalancer -
        Ingress      - 
    > kube-proxy
        every single node or member of a k8s cluster has a program called the kube-proxy
            > it is the 'one single window to the outside world'
    > NodePort Service
        nodePort property range:
            - random between 30000-32767
    > kubectl apply -f <filename"
        kubectl - CLI we use to change our Kubernetes cluster
        apply - change the current configuration of our cluster
        -f - we want to specify a file taht has the config changes
        <filename> - path to the file with the config
    > kubectl get [pods|services|*other-objects*]
        when getting services it will only report on:
            port: port that other objects will try and access to reference other pods that the service points to
            nodePort: the port we would use to try and access the service from maybe our browser
    > when we interact with the kubectl CLI command:
        when we pass a file or commands, we are nearly all the time are interacting with the 'master'.
        this performs monitoring and delegation to seperate nodes running a docker instance
    > kubernetes takeaways
        - kubnernetes is a system to deploy containerized apps
        - 'Nodes' are individual machines (or vm's) that run containers
        - 'Masters' are machines (or vm's) with a set of programs to manage nodes
        - Kubernetes did build our images - it got them from somewhere else
        - Kubernetes (the master) decided where to run each container
            \ each node can run a dissimilar set of containers
        - To deploy something, we update the desired state of the master with a config file
        - The master works constatly to meet your desired state
    > kubernetes (kubectl)
        - has the capabilities to perform commands/changes with both a 'Imperative Approach' and 'Declarative Approach'
    > Imperative vs Declative difference (running a new image)
        Imperative
            1. run a command to list out current running pods
            2. run a command to update the current pod to use a new image
        Declarative
            1. update our config file that originally created the pod
            2. throw the updated config file into kubectl
    > kubernetes config-file unique identifier
        'Name' & 'Kind' are our unique identifiers in a kubernetes config file
            e.g.:
                Name: client-pod
                Kind: pod
                image: multi-worker
    > kubectl describe <object type> <object name>
        get detailed info about an object
            kubectl - CLI we use to change our kubernetes cluster
            describe - we want to get detailed info
            <object type> - specifies the type of object we want to get info about
            <object name> - name of object
                optional: if not mentioned, will get all objects and their detailed information
    > when a pod is created there are some fields in the pod config that 'can' and 'cant' be updated when
      a pod is already running
        - this is where we can make use of deployments
    > kubectl delete -f <config file>
        remove an object (with an imperative update) specified according to configuration file
            kubectl - CLI we use to change our Kubernetes cluster
            delete - we want to delete a running object
            -f - specifies that we want to feed in a file to say what to delete
            <filename> - path to config file that created this object
    > docker build and tag with a version number
        docker build -t gyuri/multi-client:<version> ... e.g.
            docker build -t gyuri/multi-client:v2
    > imperative command to update image
        kubectl set image <object_type>/<object_name> <container_name>=<new image to use>
            e.g. kubectl set image deployment/client-deployment client=gyuri/multi-client:v2
                kubectl - CLI we use to change our kubernetes cluster
                set - we want to change a property
                image - we want to change the 'image' property
                <object_type> - type of object
                <object_name> - name of object
                <container_name> - name of the container we are updating (get this from config file)
                <new image to use> - full name of image to use with tag
    > config files passed into kubectl can contain multiple object definitions with "---" as seperator
        cat client-deployment.yaml > client.yaml
        echo "---" >> client.yaml
        cat client-cluster-ip-service.yaml >> client.yaml
    > when implementing config files into kubectl
        you can just pass in the directory and the entire pool of config files will be passed in and implemented
    > there are several different implementations of a ingress
    > to avoid looking into the incorrect documentation, ingress-nginsx is not the same as kubernetes-ingress
        ingress-nginx      = github.com/kubernetes/ingress-nginx
        kubernetes-ingress = github.com/nginxinc/kubernetes-ingress
    > setup of ingress-nginx will be very different between local, google cloud, aws & azure
    > good read on understanding ingress-nginx a bit better
        https://www.joyfulbikeshedding.com/blog/2018-03-26-studying-the-kubernetes-ingress-system.html
